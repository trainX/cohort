{"paragraphs":[{"text":"%pyspark\n\n# Load Data using a Dataframe versus using RDD's - it's so much easier\n\ngpa_df = sqlContext.read.load (\"/data/raw/gpa_data.csv\",\n        format='com.databricks.spark.csv',\n        header='true',\n        inferSchema='true')\n        \n# Show our dataframe\n\ngpa_df.show()\n\n\n","user":"mack","dateUpdated":"2018-09-10T19:43:15-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+-----+\n|hs_gpa|c_gpa|\n+------+-----+\n|  3.14|3.323|\n|  2.69| 3.34|\n|   3.0|  3.1|\n|   2.8|  3.0|\n|   2.9| 2.95|\n+------+-----+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=0","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=1","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=2"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1536456274506_-347610092","id":"20180908-212434_119996049","dateCreated":"2018-09-08T21:24:34-0400","dateStarted":"2018-09-10T19:43:15-0400","dateFinished":"2018-09-10T19:45:37-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2169"},{"text":"%pyspark\n\n\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler\n\n# Create an instance of the LinearRegression Model\n# https://spark.apache.org/docs/2.3.1/ml-classification-regression.html#linear-regression\n# https://spark.apache.org/docs/2.3.1/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegression\n\nlr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n\n# Assign Feature and Label Vectors\n\nlr.setFeaturesCol(\"hs_gpa_vector\")\nlr.setLabelCol(\"c_gpa\")\n\n# Turn into a vector\nassembler = VectorAssembler(inputCols=[\"hs_gpa\"],outputCol=\"hs_gpa_vector\")\n\noutput = assembler.transform(gpa_df)\n\nprint(\"Transformed dataset\")\n\noutput.show()\n\n# Split up the dataset into testing and training datasets\n\nsplit = output.randomSplit([0.6,0.4])\n\ntraining = split[0]\ntesting = split[1]\n\nprint(\"Transformed Training dataset\")\n\ntraining.show()\n\nprint(\"Transformed Testing dataset\")\n\ntesting.show()\n\n# Build Model based on trainging dataset\n\nmodel = lr.fit(training)\n\n# Predict against the testing dataset\n\npredictions = model.transform(testing)\n\npredictions.show()\n\n\n\n\n\n\n\n\n","user":"mack","dateUpdated":"2018-09-10T19:52:16-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","tableHide":false,"lineNumbers":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Transformed dataset\n+------+-----+-------------+\n|hs_gpa|c_gpa|hs_gpa_vector|\n+------+-----+-------------+\n|  3.14|3.323|       [3.14]|\n|  2.69| 3.34|       [2.69]|\n|   3.0|  3.1|        [3.0]|\n|   2.8|  3.0|        [2.8]|\n|   2.9| 2.95|        [2.9]|\n+------+-----+-------------+\n\nTransformed Training dataset\n+------+-----+-------------+\n|hs_gpa|c_gpa|hs_gpa_vector|\n+------+-----+-------------+\n|   2.8|  3.0|        [2.8]|\n|   3.0|  3.1|        [3.0]|\n+------+-----+-------------+\n\nTransformed Testing dataset\n+------+-----+-------------+\n|hs_gpa|c_gpa|hs_gpa_vector|\n+------+-----+-------------+\n|  2.69| 3.34|       [2.69]|\n|   2.9| 2.95|        [2.9]|\n|  3.14|3.323|       [3.14]|\n+------+-----+-------------+\n\n+------+-----+-------------+----------+\n|hs_gpa|c_gpa|hs_gpa_vector|prediction|\n+------+-----+-------------+----------+\n|  2.69| 3.34|       [2.69]|      3.05|\n|   2.9| 2.95|        [2.9]|      3.05|\n|  3.14|3.323|       [3.14]|      3.05|\n+------+-----+-------------+----------+\n\n"}]},"apps":[],"jobName":"paragraph_1536532938659_1884556398","id":"20180909-184218_103257949","dateCreated":"2018-09-09T18:42:18-0400","dateStarted":"2018-09-10T19:51:38-0400","dateFinished":"2018-09-10T19:51:44-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2170","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=27","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=28","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=29","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=30","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=31","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=32","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=33","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=34","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=35"],"interpreterSettingId":"spark2"}}},{"text":"%pyspark\n\n# TODO: Only show the predicted value\n# Hint: use the \"select\" method\n","user":"mack","dateUpdated":"2018-09-10T17:41:06-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1536536528995_-1798544344","id":"20180909-194208_145970184","dateCreated":"2018-09-09T19:42:08-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2171"},{"text":"%pyspark\n# TODO: Predict based on a single high school GPA value\n# Hint: Create a dataframe with just one high school GPA value\nfrom pyspark.ml.linalg import Vectors\n\n\nhs_gpa = spark.createDataFrame([(Vectors.dense(2.9),)], [\"FILL ME IN\"])\n\ncollege_gpa_pred = model.transform(hs_gpa)\n\ncollege_gpa_pred.show()\n","user":"mack","dateUpdated":"2018-09-10T17:50:10-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+------------------+\n|c_gpa_vector|        prediction|\n+------------+------------------+\n|       [2.9]|2.8825000000000003|\n+------------+------------------+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=60","http://hdp30-centOS75-3.trainx.ai:4040/jobs/job?id=61"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1536615656517_296090961","id":"20180910-174056_622735193","dateCreated":"2018-09-10T17:40:56-0400","dateStarted":"2018-09-10T17:47:47-0400","dateFinished":"2018-09-10T17:48:08-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:2172"},{"text":"%pyspark\n# TODO: Add another feature to the dataset\n\n","user":"mack","dateUpdated":"2018-09-10T17:50:53-0400","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1536616040108_318654965","id":"20180910-174720_430296474","dateCreated":"2018-09-10T17:47:20-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:2173"}],"name":"Week 2 / Predict College GPA","id":"2DRSSP8QB","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"jdbc:shared_process":[],"spark2:mack:":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}